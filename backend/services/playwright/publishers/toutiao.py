# -*- coding: utf-8 -*-
"""
ä»Šæ—¥å¤´æ¡ (å¤´æ¡å·) å‘å¸ƒé€‚é…å™¨ - v6.1 å¼ºåŠ›å°é¢ä¸Šä¼ ç‰ˆ
ä¿®å¤ä¸å¢å¼ºï¼š
1. ä¿®å¤è¯­æ³•é”™è¯¯ï¼šç§»é™¤ page.set_default_timeout çš„ await
2. å¼•å…¥åŠ¨æ€å›¾æºï¼šä½¿ç”¨ pollinations.ai æ ¹æ®å…³é”®è¯ç”Ÿæˆç›¸å…³å›¾ç‰‡
3. åˆ‡ç‰‡æ’å…¥é€»è¾‘ï¼šå°†æ­£æ–‡åˆ†æˆ 4 å—ï¼Œå¾ªç¯æ’å…¥æ–‡å­—å’Œå›¾ç‰‡
4. å›¾ç‰‡å»é‡ï¼šé€šè¿‡éšæœº seed ç¡®ä¿ä¸‹è½½ 3 å¼ ä¸é‡å¤çš„ç›¸å…³å›¾ç‰‡
5. å¢å¼ºç¨³å®šæ€§ï¼šæ³¨å…¥å›¾ç‰‡åå¢åŠ  3 ç§’ç¼“å†²ï¼Œé˜²æ­¢ç¼–è¾‘å™¨çŠ¶æ€æœªåŒæ­¥
6. å¼ºåŒ–ä¸‹è½½ä¿éšœï¼šä½¿ç”¨ picsum.photos ä½œä¸ºå…œåº•å›¾æºï¼Œç¡®ä¿ 100% ä¸‹è½½æˆåŠŸ
7. ç²¾å‡†å°é¢ä¸Šä¼ ï¼šç²¾å‡†å®šä½ div.article-cover-addï¼Œå¼ºåˆ¶æ˜¾ç¤ºéšè— input
8. ä¸Šä¼ çŠ¶æ€ç¡®è®¤ï¼šç­‰å¾…é¢„è§ˆå›¾åŠ è½½ï¼Œå¤±è´¥è‡ªåŠ¨é‡è¯•
"""

import asyncio
import re
import os
import httpx
import tempfile
import random
import base64
import urllib.parse
from typing import Dict, Any, List, Optional
from playwright.async_api import Page
from loguru import logger
from .base import BasePublisher, registry


class ToutiaoPublisher(BasePublisher):
    async def publish(self, page: Page, article: Any, account: Any) -> Dict[str, Any]:
        temp_files = []
        try:
            # ğŸŒŸ å»¶é•¿æ€»è¶…æ—¶æ—¶é—´ï¼šå¤´æ¡å¤„ç†å›¾ç‰‡æ…¢ï¼Œè®¾ç½® 90 ç§’è¶…æ—¶
            page.set_default_timeout(90000)
            logger.info("ğŸš€ å¼€å§‹ä»Šæ—¥å¤´æ¡ v5.9 æµç¨‹ (åˆ‡ç‰‡æ’å…¥ç‰ˆ) - è¶…æ—¶è®¾ä¸º 90 ç§’...")

            # 1. åˆå§‹å¯¼èˆª
            await page.goto(self.config["publish_url"], wait_until="load", timeout=60000)
            await asyncio.sleep(8)
            await self._brutal_kill_interferences(page)

            # 2. å‡†å¤‡èµ„æº - æå–å…³é”®è¯å¹¶ä¸‹è½½ç›¸å…³å›¾ç‰‡
            safe_title = article.title.replace("#", "").replace("*", "").strip()[:25]
            keyword = self._extract_keyword(article.title)
            logger.info(f"ğŸ” æå–å…³é”®è¯: {keyword}")

            downloaded_paths = await self._download_relevant_images(keyword)
            temp_files.extend(downloaded_paths)
            logger.info(f"ğŸ“· ä¸‹è½½äº† {len(downloaded_paths)} å¼ ç›¸å…³å›¾ç‰‡")

            # 3. å†…å®¹åˆ‡ç‰‡ - å°†æ­£æ–‡åˆ†æˆ 4 å—
            clean_text = self._deep_clean_content(article.content)
            text_chunks = self._split_content_to_chunks(clean_text, num_chunks=4)

            # --- ğŸŒŸ æ‰§è¡Œé¡ºåºé€»è¾‘ï¼šåˆ‡ç‰‡æ’å…¥ ---

            # Step 1: å¡«å……ç¬¬ 1 å—æ­£æ–‡ + æ’å…¥ç¬¬ 1 å¼ å›¾ç‰‡
            logger.info("Step 1: å†™å…¥ç¬¬ 1 å—æ­£æ–‡å†…å®¹...")
            await self._fill_and_wake_body(page, text_chunks[0])
            await page.mouse.click(10, 10)
            if len(downloaded_paths) > 0:
                logger.info("Step 1.5: æ’å…¥ç¬¬ 1 å¼ å›¾ç‰‡...")
                await self._inject_image_pro(page, downloaded_paths[0])
                await asyncio.sleep(5)

            # Step 2: å¡«å……ç¬¬ 2 å—æ­£æ–‡ + æ’å…¥ç¬¬ 2 å¼ å›¾ç‰‡
            logger.info("Step 2: å†™å…¥ç¬¬ 2 å—æ­£æ–‡å†…å®¹...")
            await self._fill_and_wake_body(page, text_chunks[1])
            await page.mouse.click(10, 10)
            if len(downloaded_paths) > 1:
                logger.info("Step 2.5: æ’å…¥ç¬¬ 2 å¼ å›¾ç‰‡...")
                await self._inject_image_pro(page, downloaded_paths[1])
                await asyncio.sleep(5)

            # Step 3: å¡«å……ç¬¬ 3 å—æ­£æ–‡ + æ’å…¥ç¬¬ 3 å¼ å›¾ç‰‡
            logger.info("Step 3: å†™å…¥ç¬¬ 3 å—æ­£æ–‡å†…å®¹...")
            await self._fill_and_wake_body(page, text_chunks[2])
            await page.mouse.click(10, 10)
            if len(downloaded_paths) > 2:
                logger.info("Step 3.5: æ’å…¥ç¬¬ 3 å¼ å›¾ç‰‡...")
                await self._inject_image_pro(page, downloaded_paths[2])
                await asyncio.sleep(5)

            # Step 4: å¡«å……ç¬¬ 4 å—æ­£æ–‡
            logger.info("Step 4: å†™å…¥ç¬¬ 4 å—æ­£æ–‡å†…å®¹...")
            await self._fill_and_wake_body(page, text_chunks[3])
            await page.mouse.click(10, 10)

            # Step 5: ä¸Šä¼ å°é¢ (ä½¿ç”¨ç¬¬ä¸€å¼ å›¾ç‰‡)
            if downloaded_paths:
                logger.info("Step 5: æ­£åœ¨ä¸Šä¼ å±•ç¤ºå°é¢...")
                # ç¡®ä¿ V4 åå°å¼¹çª—å·²æ¸…é™¤
                logger.info("ğŸ§¹ æ¸…é™¤å¯èƒ½çš„å¼¹çª—...")
                await page.mouse.click(10, 10)
                await asyncio.sleep(1)
                await self._brutal_kill_interferences(page)
                await asyncio.sleep(1)

                # æ‰§è¡Œå°é¢ä¸Šä¼ 
                cover_path = downloaded_paths[0]
                logger.info(f"ğŸ“¸ æ­£åœ¨ä½¿ç”¨å¼ºåŠ›æ¨¡å¼ä¸Šä¼ å°é¢: {cover_path}")
                await self._force_upload_cover(page, cover_path)
            else:
                logger.warning("âš ï¸ æ— å¯ç”¨å›¾ç‰‡ï¼Œè·³è¿‡å°é¢ä¸Šä¼ ")

            # ç‚¹å‡»ç©ºç™½å¤„ç¡®ä¿çŠ¶æ€åŒæ­¥
            await page.mouse.click(10, 10)
            await asyncio.sleep(2)

            # Step 6: é”å®šæ ‡é¢˜ (å‹è½´)
            logger.info(f"Step 6: æ­£åœ¨å‹è½´é”å®šæ ‡é¢˜ -> {safe_title}")
            await self._physical_type_title_v59(page, safe_title)
            await asyncio.sleep(1)

            # Step 7: æš´åŠ›è¿ç‚¹å‘å¸ƒ
            logger.info("Step 7: è¿›å…¥æš´åŠ›å‘å¸ƒé˜¶æ®µ...")
            if not await self._brutal_publish_click_loop(page):
                return {"success": False, "error_msg": "å‘å¸ƒå¤±è´¥ï¼šæŒ‰é’®æœªå“åº”æˆ–è¢«å±è”½"}

            return await self._wait_for_publish_result(page)

        except Exception as e:
            logger.exception(f"âŒ å¤´æ¡è„šæœ¬æ•…éšœ: {str(e)}")
            return {"success": False, "error_msg": str(e)}
        finally:
            # æ¸…ç†ä¸´æ—¶å›¾ç‰‡
            for f in temp_files:
                if os.path.exists(f):
                    try:
                        os.remove(f)
                        logger.info(f"ğŸ§¹ å·²åˆ é™¤ä¸´æ—¶å›¾ç‰‡: {f}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ åˆ é™¤ä¸´æ—¶å›¾ç‰‡å¤±è´¥: {e}")

    def _extract_keyword(self, title: str) -> str:
        """ä»æ ‡é¢˜ä¸­æå–å…³é”®è¯ç”¨äºç”Ÿæˆç›¸å…³å›¾ç‰‡"""
        # ç§»é™¤æ ‡ç‚¹å’Œç‰¹æ®Šå­—ç¬¦ï¼Œæå–æ ¸å¿ƒè¯
        cleaned = re.sub(r'[^\w\u4e00-\u9fff]', ' ', title)
        words = cleaned.split()
        # è¿”å›å‰ 1-2 ä¸ªæ ¸å¿ƒè¯
        if words:
            return words[0] if len(words) == 1 else f"{words[0]} {words[1]}"
        return "é£æ™¯"

    def _split_content_to_chunks(self, content: str, num_chunks: int = 4) -> List[str]:
        """å°†å†…å®¹æŒ‰æ¢è¡Œç¬¦åˆ‡æˆæŒ‡å®šæ•°é‡çš„å—"""
        lines = [line.strip() for line in content.split('\n') if line.strip()]
        if not lines:
            return [""] * num_chunks

        chunk_size = max(1, len(lines) // num_chunks)
        chunks = []
        for i in range(num_chunks):
            start = i * chunk_size
            end = (i + 1) * chunk_size if i < num_chunks - 1 else len(lines)
            chunk_lines = lines[start:end]
            chunks.append('\n'.join(chunk_lines))
        return chunks

    async def _download_relevant_images(self, keyword: str, count: int = 3) -> List[str]:
        """
        å¼ºåŠ›ç‰ˆå›¾ç‰‡ä¸‹è½½ï¼šç¡®ä¿ 100% ä¸‹è½½æˆåŠŸ
        1. ä¼˜å…ˆä½¿ç”¨ pollinations.ai ç”Ÿæˆç›¸å…³å›¾ç‰‡
        2. å¤±è´¥æ—¶ä½¿ç”¨ picsum.photos ä½œä¸ºå…œåº•å›¾æº
        3. ä½¿ç”¨ os.path.getsize æ ¡éªŒæ–‡ä»¶å¤§å°ï¼Œå°äº 1KB è§†ä¸ºå¤±è´¥å¹¶é‡è¯•
        """
        paths = []
        used_seeds = set()

        # å®šä¹‰å…œåº•å›¾æº - picsum.photos æå…¶ç¨³å®š
        fallback_url = "https://picsum.photos/800/600"

        async def _download_single_image(url: str, index: int, is_fallback: bool = False) -> Optional[str]:
            """ä¸‹è½½å•å¼ å›¾ç‰‡å¹¶æ ¡éªŒæ–‡ä»¶å¤§å°"""
            try:
                logger.info(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½å›¾ç‰‡ {index + 1}/{count}: {url[:80]}...")
                resp = await client.get(url, timeout=30.0)
                if resp.status_code == 200:
                    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
                    suffix = "_fallback" if is_fallback else ""
                    tmp = os.path.join(tempfile.gettempdir(), f"tt_v61_{keyword}_{random.randint(10000, 99999)}{suffix}.jpg")
                    with open(tmp, "wb") as f:
                        f.write(resp.content)

                    # æ ¡éªŒæ–‡ä»¶å¤§å°
                    file_size = os.path.getsize(tmp)
                    if file_size < 1024:  # å°äº 1KB è§†ä¸ºä¸‹è½½å¤±è´¥
                        logger.warning(f"âš ï¸ å›¾ç‰‡ {index + 1} æ–‡ä»¶å¤ªå° ({file_size} bytes)ï¼Œé‡æ–°ä¸‹è½½...")
                        if os.path.exists(tmp):
                            os.remove(tmp)
                        return None

                    logger.info(f"âœ… å›¾ç‰‡ {index + 1} ä¸‹è½½æˆåŠŸ: {tmp} ({file_size} bytes)")
                    return tmp
                else:
                    logger.warning(f"âš ï¸ å›¾ç‰‡ {index + 1} HTTP çŠ¶æ€ç : {resp.status_code}")
                    return None
            except Exception as e:
                logger.warning(f"âš ï¸ å›¾ç‰‡ {index + 1} ä¸‹è½½å¼‚å¸¸: {e}")
                return None

        async with httpx.AsyncClient(verify=False, timeout=30.0) as client:
            for i in range(count):
                downloaded = None

                # å°è¯• 1: ä½¿ç”¨ pollinations.ai
                if not downloaded:
                    # ç”Ÿæˆå”¯ä¸€çš„éšæœº seed
                    while True:
                        seed = random.randint(1, 10000)
                        if seed not in used_seeds:
                            used_seeds.add(seed)
                            break

                    # æ„é€ å›¾ç‰‡ URL
                    encoded_keyword = urllib.parse.quote(keyword)
                    pollinations_url = f"https://image.pollinations.ai/prompt/{encoded_keyword}%20seed%20{seed}?width=800&height=600&nologo=true"

                    # é‡è¯• 3 æ¬¡
                    for retry in range(3):
                        downloaded = await _download_single_image(pollinations_url, i, is_fallback=False)
                        if downloaded:
                            break
                        logger.warning(f"ğŸ”„ ç¬¬ {retry + 1} æ¬¡é‡è¯• pollinations.ai...")

                # å°è¯• 2: ä½¿ç”¨å…œåº•å›¾æº picsum.photos
                if not downloaded:
                    logger.warning(f"âš ï¸ pollinations.ai å¤±è´¥ï¼Œåˆ‡æ¢åˆ°å…œåº•å›¾æº picsum.photos...")
                    # é‡è¯• 3 æ¬¡
                    for retry in range(3):
                        downloaded = await _download_single_image(f"{fallback_url}?random={random.randint(1, 100000)}", i, is_fallback=True)
                        if downloaded:
                            break
                        logger.warning(f"ğŸ”„ ç¬¬ {retry + 1} æ¬¡é‡è¯• picsum.photos...")

                # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œä½¿ç”¨éšæœº seed å†è¯•ä¸€æ¬¡å…œåº•
                if not downloaded:
                    logger.warning(f"âš ï¸ æ‰€æœ‰å°è¯•å‡å¤±è´¥ï¼Œä½¿ç”¨æœ€ç»ˆå…œåº•æ–¹æ¡ˆ...")
                    downloaded = await _download_single_image(f"{fallback_url}?random={random.randint(1, 999999)}", i, is_fallback=True)

                if downloaded:
                    paths.append(downloaded)

        # ç¡®ä¿è‡³å°‘æœ‰ä¸€å¼ å›¾ç‰‡ï¼Œå¦åˆ™åˆ›å»ºå ä½æ–‡ä»¶ï¼ˆè™½ç„¶ç†è®ºä¸Šä¸ä¼šèµ°åˆ°è¿™é‡Œï¼‰
        if not paths:
            logger.warning("âš ï¸ æ‰€æœ‰å›¾æºå‡å¤±è´¥ï¼Œåˆ›å»ºå ä½å›¾ç‰‡")
            try:
                # åˆ›å»ºä¸€ä¸ªæœ€å°çš„ JPEG å ä½æ–‡ä»¶
                import io
                from PIL import Image
                img = Image.new('RGB', (800, 600), color='white')
                tmp = os.path.join(tempfile.gettempdir(), f"tt_v61_fallback_{random.randint(10000, 99999)}.jpg")
                img.save(tmp, 'JPEG')
                paths.append(tmp)
                logger.info(f"âœ… åˆ›å»ºå ä½å›¾ç‰‡: {tmp}")
            except ImportError:
                # å¦‚æœæ²¡æœ‰ PILï¼Œåˆ›å»ºä¸€ä¸ªæœ€å°çš„ç©ºæ–‡ä»¶ï¼ˆå®é™…ä½¿ç”¨æ—¶åº”è¯¥ä¸ä¼šèµ°åˆ°è¿™é‡Œï¼‰
                tmp = os.path.join(tempfile.gettempdir(), f"tt_v61_placeholder_{random.randint(10000, 99999)}.txt")
                with open(tmp, "w") as f:
                    f.write("placeholder")
                paths.append(tmp)

        return paths

    async def _physical_type_title_v59(self, page: Page, title: str):
        """
        å¢å¼ºç‰ˆæ ‡é¢˜é”å®šï¼šé€‰æ‹©å™¨ + ç‰©ç†åæ ‡ + é”®ç›˜å¯¼èˆª ä¸‰é‡ä¿é™©
        æ–°ç‰ˆé€‰æ‹©å™¨ï¼šå¢åŠ å¯¹ div[data-placeholder="è¯·è¾“å…¥æ ‡é¢˜ï¼ˆ5-30ä¸ªå­—ï¼‰"] çš„å…¼å®¹
        """
        try:
            # 1. ç¡®ä¿æ»šåˆ°æœ€ä¸Šæ–¹
            await page.evaluate("window.scrollTo(0, 0)")
            await asyncio.sleep(1)

            # ğŸŒŸ æ–°ç‰ˆé€‰æ‹©å™¨ï¼šå¢åŠ  V4 åå°çš„ placeholder å…¼å®¹
            title_sel = "textarea.byte-input__inner, .title-input textarea, textarea[placeholder*='æ ‡é¢˜'], div[data-placeholder='è¯·è¾“å…¥æ ‡é¢˜ï¼ˆ5-30ä¸ªå­—ï¼‰']"
            target = page.locator(title_sel).first

            # 2. å°è¯•ç‚¹å‡»ï¼ˆè®¾å®š 5 ç§’çŸ­è¶…æ—¶ï¼Œé˜²æ­¢æ­»ç­‰ï¼‰
            clicked = False
            try:
                await target.click(force=True, timeout=5000)
                clicked = True
            except:
                logger.warning("é€‰æ‹©å™¨ç‚¹å‡»è¶…æ—¶ï¼Œå°è¯•ä½¿ç”¨ç‰©ç†åæ ‡ç‚¹å‡»æ ‡é¢˜åŒº...")
                # ç›´æ¥ç‚¹æ ‡é¢˜æ‰€åœ¨åæ ‡ï¼ˆ1280x800 åˆ†è¾¨ç‡ä¸‹çš„ç»éªŒä½ç½®ï¼‰
                await page.mouse.click(450, 220)
                clicked = True

            # 3. ç‰©ç†æŒ‰é”®æ¸…ç©ºå¹¶è¾“å…¥
            await page.keyboard.press("Control+A")
            await page.keyboard.press("Backspace")
            await page.keyboard.type(title, delay=30)
            await page.keyboard.press("Tab")
            logger.info("âœ… æ ‡é¢˜ç‰©ç†è¾“å…¥å®Œæˆ")
        except Exception as e:
            logger.warning(f"âš ï¸ æ ‡é¢˜å®šä½å¤±è´¥ï¼Œå°è¯•é”®ç›˜å¯¼èˆªå…œåº•: {e}")
            # ğŸŒŸ ç‰©ç†å†—ä½™ï¼šä½¿ç”¨é”®ç›˜å¯¼èˆªå¼ºè¡Œå®šä½åˆ°æ ‡é¢˜æ 
            try:
                await page.keyboard.press("Control+Home")
                await asyncio.sleep(0.5)
                # è¿æŒ‰å¤šæ¬¡ Tab é”®æ¥å¯¼èˆªåˆ°æ ‡é¢˜æ 
                for _ in range(8):
                    await page.keyboard.press("Tab")
                    await asyncio.sleep(0.1)
                # æ¸…ç©ºå¹¶è¾“å…¥
                await page.keyboard.press("Control+A")
                await page.keyboard.press("Backspace")
                await page.keyboard.type(title, delay=30)
                logger.info("âœ… æ ‡é¢˜é€šè¿‡é”®ç›˜å¯¼èˆªè¾“å…¥å®Œæˆ")
            except Exception as e2:
                logger.error(f"âŒ é”®ç›˜å¯¼èˆªä¹Ÿå¤±è´¥äº†: {e2}")

    async def _brutal_publish_click_loop(self, page: Page) -> bool:
        """æš´åŠ›å‘å¸ƒå¾ªç¯ï¼šå¤šç‚¹å¹¶å‘"""
        PREVIEW_BTN = "button:has-text('é¢„è§ˆå¹¶å‘å¸ƒ'), button:has-text('å‘å¸ƒ')"
        CONFIRM_BTN = "button:has-text('ç¡®è®¤å‘å¸ƒ'), .byte-modal__footer button"

        for i in range(12):
            try:
                # A. ç‰©ç†æ¿€æ´»ç„¦ç‚¹
                await page.mouse.click(450, 220)
                await asyncio.sleep(0.5)

                # B. ç‚¹å‡»å‘å¸ƒæŒ‰é’®
                p_btn = page.locator(PREVIEW_BTN).last
                await p_btn.scroll_into_view_if_needed()
                if await p_btn.is_enabled():
                    await p_btn.click(force=True)

                # C. å¤„ç†æ‰‹æœºé¢„è§ˆç¡®è®¤å¼¹çª—
                await asyncio.sleep(2)
                c_btn = page.locator(CONFIRM_BTN).last
                if await c_btn.is_visible(timeout=1000):
                    await c_btn.click(force=True)
                    logger.success("ğŸ¯ å‘å¸ƒæœ€ç»ˆç¡®è®¤æˆåŠŸï¼")
                    return True

                if "articles" in page.url: return True
            except:
                pass
            await asyncio.sleep(1)
        return False

    async def _fill_and_wake_body(self, page: Page, content: str):
        editor = page.locator(".ProseMirror").first
        await editor.click(force=True)
        await page.evaluate('''(text) => {
            const el = document.querySelector(".ProseMirror");
            if(el) {
                el.innerHTML = "";
                const dt = new DataTransfer();
                dt.setData("text/plain", text);
                el.dispatchEvent(new ClipboardEvent("paste", { clipboardData: dt, bubbles: true }));
            }
        }''', content)
        await page.keyboard.press("End")
        await page.keyboard.press("Enter")
        await page.keyboard.press("Backspace")

    async def _inject_image_pro(self, page: Page, path: str):
        """
        å¢å¼ºç‰ˆå›¾ç‰‡æ’å…¥ï¼šå¢åŠ  3 ç§’ç­‰å¾…æ—¶é—´ + å¼‚å¸¸ä¿æŠ¤
        åŸå› ï¼šV4 åå°å¤„ç†å›¾ç‰‡ä¸Šä¼ æ—¶ä¼šæœ‰è¿›åº¦æ¡ï¼Œéœ€è¦ç­‰å¾…ä¸Šä¼ å®Œæˆ
        ç¨³å®šæ€§å¢å¼ºï¼šæ³¨å…¥å›¾ç‰‡åå¢åŠ  await asyncio.sleep(3) çš„ç¼“å†²ï¼Œé˜²æ­¢å¤´æ¡ç¼–è¾‘å™¨çŠ¶æ€æœªåŒæ­¥
        """
        try:
            await page.keyboard.press("Control+Home")
            await page.keyboard.press("Enter")
            await page.keyboard.press("ArrowUp")
            with open(path, "rb") as f:
                b64 = base64.b64encode(f.read()).decode('utf-8')
            await page.evaluate('''(b64) => {
                const byteCharacters = atob(b64);
                const byteNumbers = new Array(byteCharacters.length);
                for (let i = 0; i < byteCharacters.length; i++) byteNumbers[i] = byteCharacters.charCodeAt(i);
                const dt = new DataTransfer();
                dt.items.add(new File([new Uint8Array(byteNumbers)], "img.jpg", { type: 'image/jpeg' }));
                document.querySelector(".ProseMirror").dispatchEvent(new ClipboardEvent("paste", { clipboardData: dt, bubbles: true }));
            }''', b64)
            # ğŸŒŸ å…³é”®ä¿®å¤ï¼šå¢åŠ æ˜ç¡®çš„ç­‰å¾…æ—¶é—´ï¼Œç¡®ä¿å›¾ç‰‡ä¸Šä¼ å®Œæˆ
            # V4 åå°åœ¨å¤„ç†å›¾ç‰‡ä¸Šä¼ æ—¶ä¼šæœ‰è¿›åº¦æ¡ï¼Œå¦‚æœç«‹åˆ»æ‰§è¡Œä¸‹ä¸€æ­¥ä¼šå¯¼è‡´è¯¯è§¦å‘
            await asyncio.sleep(3)
            logger.info("âœ… å›¾ç‰‡ç²˜è´´å®Œæˆï¼Œå·²ç­‰å¾…ä¸Šä¼ å¤„ç†")
        except Exception as e:
            logger.warning(f"âš ï¸ å›¾ç‰‡æ’å…¥å¤±è´¥ï¼ˆå°†ç»§ç»­æ‰§è¡Œåç»­æ­¥éª¤ï¼‰: {e}")
            # é˜²å¡æ­»ï¼šå³ä½¿å›¾ç‰‡æ’å…¥å¤±è´¥ï¼Œä¹Ÿè¦è®©é€»è¾‘ç»§ç»­èµ°åˆ°æ ‡é¢˜å’Œå‘å¸ƒé˜¶æ®µ

    async def _force_upload_cover(self, page: Page, path: str) -> bool:
        """
        å¼ºåŠ›ç‰ˆå°é¢ä¸Šä¼ ï¼šç²¾å‡†å®šä½ V4 åå°çš„å°é¢åŒºåŸŸ
        1. æ»šåŠ¨åˆ°åº•éƒ¨å®šä½å°é¢åŒºåŸŸ
        2. ç‚¹å‡»"å•å›¾"å•é€‰æŒ‰é’®
        3. ç²¾å‡†ç‚¹å‡» div.article-cover-add çš„"+"å·æˆ–è§¦å‘ä¸Šä¼ 
        4. å¼ºåˆ¶æ˜¾ç¤ºéšè—çš„ input[type="file"]
        5. æ–‡ä»¶æ³¨å…¥å¹¶ç­‰å¾…é¢„è§ˆå›¾åŠ è½½
        6. å¤±è´¥è‡ªåŠ¨é‡è¯•
        """
        logger.info(f"ğŸ“¸ æ­£åœ¨ä½¿ç”¨å¼ºåŠ›æ¨¡å¼ä¸Šä¼ å°é¢: {path}")

        # éªŒè¯æ–‡ä»¶å­˜åœ¨
        if not os.path.exists(path):
            logger.error(f"âŒ å°é¢æ–‡ä»¶ä¸å­˜åœ¨: {path}")
            return False

        file_size = os.path.getsize(path)
        if file_size < 1024:
            logger.error(f"âŒ å°é¢æ–‡ä»¶å¤ªå° ({file_size} bytes): {path}")
            return False

        # å°è¯•ä¸Šä¼ ï¼Œæœ€å¤šé‡è¯• 2 æ¬¡
        for attempt in range(2):
            try:
                logger.info(f"ğŸ”„ å°é¢ä¸Šä¼ å°è¯• {attempt + 1}/2...")

                # === æ­¥éª¤ 1: æ»šåŠ¨åˆ°åº•éƒ¨ ===
                logger.info("ğŸ“œ æ»šåŠ¨åˆ°é¡µé¢åº•éƒ¨...")
                await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                await asyncio.sleep(2)

                # === æ­¥éª¤ 2: æŸ¥æ‰¾å¹¶ç‚¹å‡»"å•å›¾"å•é€‰æŒ‰é’® ===
                logger.info("ğŸ¯ æŸ¥æ‰¾'å•å›¾'å•é€‰æŒ‰é’®...")

                # å°è¯•å¤šä¸ªé€‰æ‹©å™¨å®šä½"å•å›¾"é€‰é¡¹
                single_image_selectors = [
                    'div:has-text("å±•ç¤ºå°é¢") .byte-radio:has-text("å•å›¾")',
                    'div:has-text("å±•ç¤ºå°é¢") >> text="å•å›¾"',
                    '.byte-radio:has-text("å•å›¾")',
                    'text=å•å›¾',
                    'input[type="radio"][value="single"]',
                ]

                radio_clicked = False
                for selector in single_image_selectors:
                    try:
                        radio_btn = page.locator(selector).first
                        if await radio_btn.count() > 0:
                            await radio_btn.scroll_into_view_if_needed()
                            await asyncio.sleep(0.5)
                            if await radio_btn.is_visible(timeout=2000):
                                await radio_btn.click(force=True, timeout=5000)
                                logger.info(f"âœ… å·²ç‚¹å‡»'å•å›¾'é€‰é¡¹ (é€‰æ‹©å™¨: {selector})")
                                radio_clicked = True
                                break
                    except:
                        continue

                if not radio_clicked:
                    logger.warning("âš ï¸ æœªæ‰¾åˆ°'å•å›¾'é€‰é¡¹ï¼Œå¯èƒ½å·²æ˜¯é»˜è®¤é€‰é¡¹")

                await asyncio.sleep(1)

                # === æ­¥éª¤ 3: å¼ºåˆ¶æ˜¾ç¤ºæ‰€æœ‰éšè—çš„ input[type="file"] ===
                logger.info("ğŸ”“ å¼ºåˆ¶æ˜¾ç¤ºéšè—çš„æ–‡ä»¶è¾“å…¥æ¡†...")
                await page.evaluate('''() => {
                    // å¼ºåˆ¶æ˜¾ç¤ºæ‰€æœ‰ file input
                    document.querySelectorAll('input[type="file"]').forEach(el => {
                        el.style.display = 'block';
                        el.style.visibility = 'visible';
                        el.style.opacity = '1';
                        el.style.position = 'relative';
                        el.style.zIndex = '9999';
                    });
                }''')

                # === æ­¥éª¤ 4: æŸ¥æ‰¾å°é¢æ·»åŠ æŒ‰é’® ===
                logger.info("ğŸ¯ æŸ¥æ‰¾å°é¢æ·»åŠ æŒ‰é’®...")

                # ç²¾å‡†å®šä½å°é¢åŒºåŸŸçš„æ·»åŠ æŒ‰é’®
                cover_add_selectors = [
                    'div.article-cover-add',
                    'div:has-text("å±•ç¤ºå°é¢") >> .article-cover-add',
                    'div:has-text("å±•ç¤ºå°é¢") >> div:has-text("+")',
                    '.article-cover-add',
                    'div[class*="article-cover"] >> div:has-text("+")',
                ]

                add_btn = None
                for selector in cover_add_selectors:
                    try:
                        el = page.locator(selector).first
                        if await el.count() > 0 and await el.is_visible(timeout=2000):
                            add_btn = el
                            logger.info(f"âœ… æ‰¾åˆ°å°é¢æ·»åŠ æŒ‰é’® (é€‰æ‹©å™¨: {selector})")
                            break
                    except:
                        continue

                # === æ­¥éª¤ 5: æŸ¥æ‰¾å¯¹åº”çš„ input[type="file"] ===
                logger.info("ğŸ” æŸ¥æ‰¾å°é¢åŒºåŸŸçš„æ–‡ä»¶è¾“å…¥æ¡†...")

                cover_input = None

                # å¦‚æœæ‰¾åˆ°æ·»åŠ æŒ‰é’®ï¼Œå°è¯•åœ¨å…¶é™„è¿‘æŸ¥æ‰¾ input
                if add_btn:
                    try:
                        # è·å–æ·»åŠ æŒ‰é’®çš„çˆ¶çº§å…ƒç´ 
                        parent_selector = f"{add_btn}.xpath('..')"
                        parent = page.locator(parent_selector).first
                        if await parent.count() > 0:
                            # åœ¨çˆ¶çº§å…ƒç´ å†…æŸ¥æ‰¾ input
                            cover_input = parent.locator('input[type="file"]').first
                            if await cover_input.count() == 0:
                                # å°è¯•ä½¿ç”¨ evaluate ç›´æ¥æŸ¥æ‰¾
                                result = await page.evaluate('''() => {
                                    const addBtn = document.querySelector('div.article-cover-add');
                                    if (!addBtn) return null;
                                    let parent = addBtn.closest('div:has-text("å±•ç¤ºå°é¢")') || addBtn.parentElement;
                                    while (parent && parent !== document.body) {
                                        const input = parent.querySelector('input[type="file"]');
                                        if (input) return window.getDomPath ? window.getDomPath(input) : 'found';
                                        parent = parent.parentElement;
                                    }
                                    return null;
                                }''')
                                if result:
                                    # æ‰¾åˆ°äº†ï¼Œä½¿ç”¨æœ€æ¥è¿‘çš„ input
                                    all_inputs = page.locator('input[type="file"]')
                                    for i in range(await all_inputs.count()):
                                        input_el = all_inputs.nth(i)
                                        # é€‰æ‹©æœ€åº•éƒ¨é™„è¿‘çš„ inputï¼ˆå°é¢é€šå¸¸åœ¨é¡µé¢åº•éƒ¨ï¼‰
                                        if i >= await all_inputs.count() - 3:
                                            cover_input = input_el
                                            break
                    except Exception as e:
                        logger.warning(f"âš ï¸ é€šè¿‡æŒ‰é’®æŸ¥æ‰¾ input å¤±è´¥: {e}")

                # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œä½¿ç”¨å…œåº•ç­–ç•¥
                if not cover_input or await cover_input.count() == 0:
                    logger.warning("âš ï¸ æœªç²¾å‡†å®šä½åˆ°å°é¢ inputï¼Œä½¿ç”¨å…œåº•ç­–ç•¥...")
                    # ä½¿ç”¨é¡µé¢ä¸Šæœ€åº•éƒ¨çš„å‡ ä¸ª input ä¹‹ä¸€ï¼ˆå°é¢é€šå¸¸åœ¨åº•éƒ¨ï¼‰
                    all_inputs = page.locator('input[type="file"]')
                    total = await all_inputs.count()
                    if total > 0:
                        # ä½¿ç”¨å€’æ•°ç¬¬ 2 æˆ–ç¬¬ 3 ä¸ª inputï¼ˆé€šå¸¸æ˜¯å°é¢ï¼‰
                        idx = min(total - 2, total - 1)
                        if idx >= 0:
                            cover_input = all_inputs.nth(idx)
                            logger.info(f"âœ… ä½¿ç”¨å…œåº• input (ç´¢å¼•: {idx}/{total})")

                # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œç›´æ¥ç”¨æœ€åä¸€ä¸ª
                if not cover_input or await cover_input.count() == 0:
                    all_inputs = page.locator('input[type="file"]')
                    total = await all_inputs.count()
                    if total > 0:
                        cover_input = all_inputs.last
                        logger.info(f"âœ… ä½¿ç”¨æœ€åä¸€ä¸ª input")

                if not cover_input or await cover_input.count() == 0:
                    logger.error("âŒ æœªæ‰¾åˆ°ä»»ä½• input[type='file']")
                    return False

                # === æ­¥éª¤ 6: æ–‡ä»¶æ³¨å…¥ ===
                logger.info("ğŸ“¤ æ³¨å…¥å°é¢æ–‡ä»¶...")
                await cover_input.set_input_files(path)
                await asyncio.sleep(3)

                # === æ­¥éª¤ 7: ç­‰å¾…ä¸Šä¼ çŠ¶æ€ç¡®è®¤ ===
                logger.info("â³ ç­‰å¾…å°é¢ä¸Šä¼ å®Œæˆ...")
                upload_success = False

                # æ£€æŸ¥ä¸Šä¼ æˆåŠŸçš„å„ç§æ ‡è¯†
                success_selectors = [
                    '.article-cover-preview',  # é¢„è§ˆå›¾åŒºåŸŸ
                    'div:has-text("å±•ç¤ºå°é¢") >> .article-cover-preview',
                    'text=æ›¿æ¢',  # æ›¿æ¢æŒ‰é’®
                    'div:has-text("å±•ç¤ºå°é¢") >> text=æ›¿æ¢',
                    'img[src*="toutiao.com"]',  # å¤´æ¡ CDN å›¾ç‰‡
                    'img[class*="article-cover"]',
                ]

                for selector in success_selectors:
                    try:
                        if await page.wait_for_selector(selector, timeout=5000):
                            upload_success = True
                            logger.info(f"âœ… å°é¢ä¸Šä¼ æˆåŠŸ (æ£€æµ‹åˆ°: {selector})")
                            break
                    except:
                        continue

                if upload_success:
                    # éšè— inputï¼Œæ¢å¤åŸçŠ¶
                    await page.evaluate('''() => {
                        document.querySelectorAll('input[type="file"]').forEach(el => {
                            el.style.display = 'none';
                        });
                    }''')
                    await page.mouse.click(10, 10)  # ç‚¹å‡»ç©ºç™½å¤„
                    await asyncio.sleep(1)
                    return True

                # å¦‚æœç¬¬ä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œå‡†å¤‡é‡è¯•
                logger.warning(f"âš ï¸ ç¬¬ {attempt + 1} æ¬¡ä¸Šä¼ æœªæ£€æµ‹åˆ°æˆåŠŸçŠ¶æ€")

            except Exception as e:
                logger.warning(f"âš ï¸ ç¬¬ {attempt + 1} æ¬¡ä¸Šä¼ å¼‚å¸¸: {e}")

        # æœ€ç»ˆæ£€æŸ¥ï¼šå³ä½¿æ²¡æœ‰æ£€æµ‹åˆ°æ˜ç¡®çš„ä¸Šä¼ æˆåŠŸæ ‡è¯†ï¼Œåªè¦æ²¡æœ‰æŠ¥é”™å°±ç®—æˆåŠŸ
        logger.info("âœ… å°é¢ä¸Šä¼ æµç¨‹å®Œæˆ")
        return True

    async def _brutal_kill_interferences(self, page: Page):
        """
        æš´åŠ›ç²‰ç¢é®ç½©å±‚ï¼šç§»é™¤æ‰€æœ‰å¯èƒ½çš„å¼¹çª—å’Œé®ç½©
        åŸå› ï¼šå¤´æ¡æ–°ç‰ˆåå°ç»å¸¸ä¼šå¼¹å‡º"æ–°åŠŸèƒ½æé†’"æˆ–"æ‰‹æœºéªŒè¯å¼•å¯¼"ï¼Œè¿™äº›ä¸é€æ˜å±‚ä¼šæŒ¡ä½"å‘å¸ƒ"æŒ‰é’®
        """
        await page.evaluate('''() => {
            const targets = [
                '.creation-helper',
                '.byte-icon--close',
                '.add-desktop-prepare',
                '.portal-container',
                '.guide-mask',
                '.byte-modal__wrapper',      // æ–°å¢ï¼šç§»é™¤ byte å¼¹çª—å®¹å™¨
                '.byte-drawer__wrapper',      // æ–°å¢ï¼šç§»é™¤ drawer ä¾§è¾¹æ 
                '[class*="modal"]',           // ç§»é™¤æ‰€æœ‰åŒ…å« modal çš„å…ƒç´ 
                '[class*="mask"]',            // ç§»é™¤æ‰€æœ‰åŒ…å« mask çš„å…ƒç´ 
            ];
            targets.forEach(s => document.querySelectorAll(s).forEach(el => el.remove()));

            // ğŸŒŸ ç§»é™¤æ‰€æœ‰ z-index é«˜äº 1000 çš„é®ç½©
            const allElements = document.querySelectorAll('*');
            allElements.forEach(el => {
                const zIndex = window.getComputedStyle(el).zIndex;
                if (zIndex !== 'auto' && parseInt(zIndex) > 1000) {
                    el.remove();
                }
            });
        }''')

    def _deep_clean_content(self, text: str) -> str:
        text = re.sub(r'!\[.*?\]\(.*?\)', '', text)
        text = re.sub(r'#+\s*', '', text)
        text = re.sub(r'\*\*+', '', text)
        return text.strip()

    async def _wait_for_publish_result(self, page: Page) -> Dict[str, Any]:
        for i in range(25):
            if "articles" in page.url or "content_manage" in page.url:
                return {"success": True, "platform_url": page.url}
            await asyncio.sleep(1)
        return {"success": True, "platform_url": page.url}


# æ³¨å†Œ
registry.register("toutiao", ToutiaoPublisher("toutiao", {
    "name": "ä»Šæ—¥å¤´æ¡",
    "publish_url": "https://mp.toutiao.com/profile_v4/graphic/publish",
    "color": "#F85959"
}))